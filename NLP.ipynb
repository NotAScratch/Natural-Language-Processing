{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import accuracy_score \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Budget</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>IMDB Rating</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109.934283</td>\n",
       "      <td>98.769439</td>\n",
       "      <td>7.178894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>97.234714</td>\n",
       "      <td>113.690320</td>\n",
       "      <td>7.280392</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>112.953771</td>\n",
       "      <td>114.859282</td>\n",
       "      <td>7.541526</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>130.460597</td>\n",
       "      <td>107.965841</td>\n",
       "      <td>7.526901</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>95.316933</td>\n",
       "      <td>117.580714</td>\n",
       "      <td>6.311165</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>42.962365</td>\n",
       "      <td>95.389100</td>\n",
       "      <td>6.142989</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>24.302982</td>\n",
       "      <td>79.627538</td>\n",
       "      <td>6.311088</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>70.308086</td>\n",
       "      <td>88.096613</td>\n",
       "      <td>5.814865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>48.281902</td>\n",
       "      <td>81.243817</td>\n",
       "      <td>6.188995</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>68.567245</td>\n",
       "      <td>76.172003</td>\n",
       "      <td>6.764110</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      Budget     Runtime  IMDB Rating  Genre\n",
       "0             0  109.934283   98.769439     7.178894    0.0\n",
       "1             1   97.234714  113.690320     7.280392    0.0\n",
       "2             2  112.953771  114.859282     7.541526    0.0\n",
       "3             3  130.460597  107.965841     7.526901    0.0\n",
       "4             4   95.316933  117.580714     6.311165    0.0\n",
       "..          ...         ...         ...          ...    ...\n",
       "195         195   42.962365   95.389100     6.142989    1.0\n",
       "196         196   24.302982   79.627538     6.311088    1.0\n",
       "197         197   70.308086   88.096613     5.814865    1.0\n",
       "198         198   48.281902   81.243817     6.188995    1.0\n",
       "199         199   68.567245   76.172003     6.764110    1.0\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gau = GaussianNB()\n",
    "gau.fit(df[['Budget','Runtime','IMDB Rating']],df['Genre'])\n",
    "\n",
    "y_pred = gau.predict(df[['Budget','Runtime','IMDB Rating']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.975"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accurecy = accuracy_score(df['Genre'],y_pred)\n",
    "accurecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"This cat sat on the mat\",\n",
    "    \"This dog sat on the log\",\n",
    "    \"The cat and the dog played together\"\n",
    "]\n",
    "\n",
    "vector = CountVectorizer(binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>log</th>\n",
       "      <th>mat</th>\n",
       "      <th>on</th>\n",
       "      <th>played</th>\n",
       "      <th>sat</th>\n",
       "      <th>the</th>\n",
       "      <th>this</th>\n",
       "      <th>together</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   and  cat  dog  log  mat  on  played  sat  the  this  together\n",
       "0    0    1    0    0    1   1       0    1    1     1         0\n",
       "1    0    0    1    1    0   1       0    1    1     1         0\n",
       "2    1    1    1    0    0   0       1    0    1     0         1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vector.fit_transform(documents)\n",
    "\n",
    "feature_names = vector.get_feature_names_out()\n",
    "\n",
    "\n",
    "\n",
    "dense_matrix = X.toarray()\n",
    "\n",
    "df = pd.DataFrame(dense_matrix,columns=vector.get_feature_names_out())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "emails = [\n",
    "    \"Suresh, the party was a blast, thanks!\",\n",
    "    \"Suresh, please let me know if you need the information\",\n",
    "    \"win a free trip to dubai\",\n",
    "    \"Suresh, can we schedule a meeting tomorrow?\",\n",
    "    \"Hey mohan, can we get together to watch footbal game tomorrow?\"\n",
    "]\n",
    "\n",
    "labels = [1,0,1,2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = CountVectorizer(binary=True)\n",
    "# X = vector.fit_transform(emails)\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,labels,test_size=0.25,random_state=42)\n",
    "\n",
    "# model = BernoulliNB()\n",
    "# model.fit(X_train,y_train)\n",
    "\n",
    "# predictions = model.predict(X_test)\n",
    "\n",
    "# predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = CountVectorizer(binary=False)\n",
    "X = vector.fit_transform(emails)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,labels,test_size=0.25,random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Hello this is a random sentence to test the model with random text data to see how it perfrms on unsen data and how well it can predict the labels of the text data (*&^*^) !@ \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]',' ',text)\n",
    "    text = re.sub(r'[\\d{1,1}]',' ',text) \n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello this is a random sentence to test the model with random text data to see how it performs on unseen data and how well it can predict the labels of the text data            '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = preprocess_text(text)\n",
    "cleaned_text"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
